{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ],
      "metadata": {
        "id": "HyehPoBqCVf-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "81JeHasmB-hy"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import Tuple\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities"
      ],
      "metadata": {
        "id": "AZpbR4g2Cfz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_periodic(f: torch.Tensor, dx: float, dy: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "  \"\"\"Compute ∂f/∂x and ∂f/∂y with second-order central differences and periodic BCs.\"\"\"\n",
        "  f_xp = torch.roll(f, shifts=-1, dims=-1)\n",
        "  f_xm = torch.roll(f, shifts=+1, dims=-1)\n",
        "  dfdx = (f_xp - f_xm) / (2.0 * dx)\n",
        "\n",
        "  f_yp = torch.roll(f, shifts=-1, dims=-2)\n",
        "  f_ym = torch.roll(f, shifts=+1, dims=-2)\n",
        "  dfdy = (f_yp - f_ym) / (2.0 * dy)\n",
        "\n",
        "  return dfdx, dfdy\n",
        "\n",
        "def laplacian_periodic(f: torch.Tensor, dx: float, dy: float) -> torch.Tensor:\n",
        "  \"\"\"5-point Laplacian with periodic BCs.\"\"\"\n",
        "  f_xp = torch.roll(f, shifts=-1, dims=-1)\n",
        "  f_xm = torch.roll(f, shifts=+1, dims=-1)\n",
        "  f_yp = torch.roll(f, shifts=-1, dims=-2)\n",
        "  f_ym = torch.roll(f, shifts=+1, dims=-2)\n",
        "  return (f_xp - 2.0 * f + f_xm) / (dx * dx) + (f_yp - 2.0 * f + f_ym) / (dy * dy)"
      ],
      "metadata": {
        "id": "fgwvSQATChS5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RK4 Integrator and Burger RHS"
      ],
      "metadata": {
        "id": "Q15izLNmCleE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def burgers_rhs(u: torch.Tensor, v: torch.Tensor, nu: float, dx: float, dy: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "  \"\"\"Compute RHS of 2D vector Burgers for fields u, v on periodic grid.\"\"\"\n",
        "  u_x, u_y = grad_periodic(u, dx, dy)\n",
        "  v_x, v_y = grad_periodic(v, dx, dy)\n",
        "\n",
        "  adv_u = u * u_x + v * u_y\n",
        "  adv_v = u * v_x + v * v_y\n",
        "\n",
        "  lap_u = laplacian_periodic(u, dx, dy)\n",
        "  lap_v = laplacian_periodic(v, dx, dy)\n",
        "\n",
        "  du_dt = -adv_u + nu * lap_u\n",
        "  dv_dt = -adv_v + nu * lap_v\n",
        "  return du_dt, dv_dt"
      ],
      "metadata": {
        "id": "bLyp2k8lCvLa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rk4_step(u: torch.Tensor, v: torch.Tensor, dt: float, nu: float, dx: float, dy: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "  k1_u, k1_v = burgers_rhs(u, v, nu, dx, dy)\n",
        "  k2_u, k2_v = burgers_rhs(u + 0.5 * dt * k1_u, v + 0.5 * dt * k1_v, nu, dx, dy)\n",
        "  k3_u, k3_v = burgers_rhs(u + 0.5 * dt * k2_u, v + 0.5 * dt * k2_v, nu, dx, dy)\n",
        "  k4_u, k4_v = burgers_rhs(u + dt * k3_u, v + dt * k3_v, nu, dx, dy)\n",
        "\n",
        "  u_next = u + (dt / 6.0) * (k1_u + 2 * k2_u + 2 * k3_u + k4_u)\n",
        "  v_next = v + (dt / 6.0) * (k1_v + 2 * k2_v + 2 * k3_v + k4_v)\n",
        "\n",
        "  return u_next, v_next"
      ],
      "metadata": {
        "id": "BIGYNlfIEiD-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def generate_smooth_random_field(batch: int, H: int, W: int, strength: float = 0.5, cutoff: float = 8.0, device=None) -> torch.Tensor:\n",
        "  \"\"\"Generate smooth periodic random scalar fields via spectral filtering.\"\"\"\n",
        "  if device is None:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "  noise = torch.randn(batch, H, W, device=device, dtype=torch.float32)\n",
        "  fhat = torch.fft.rfft2(noise)\n",
        "\n",
        "  ky = torch.fft.fftfreq(H, d=1.0).to(device).view(H, 1)\n",
        "  kx = torch.fft.rfftfreq(W, d=1.0).to(device).view(1, W // 2 + 1)\n",
        "  k2 = ky ** 2 + kx ** 2\n",
        "\n",
        "  filt = torch.exp(-k2 * (cutoff ** -2))\n",
        "  fhat_filtered = fhat * filt\n",
        "\n",
        "  field = torch.fft.irfft2(fhat_filtered, s=(H, W)).real\n",
        "\n",
        "  # More conservative normalization\n",
        "  field_std = field.std(dim=(-2, -1), keepdim=True)\n",
        "  field = strength * field / torch.clamp(field_std, min=1e-6)\n",
        "\n",
        "  # Clamp to prevent extreme value HELL\n",
        "  field = torch.clamp(field, -2.0, 2.0)\n",
        "\n",
        "  return field"
      ],
      "metadata": {
        "id": "43gFZJWkEq5y"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def synthesize_dataset(N: int, H: int, W: int, T: float, steps: int, nu: float, device=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "  \"\"\"Create a dataset: inputs X=(u0,v0), targets Y=(uT,vT).\"\"\"\n",
        "  if device is None:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "  Lx = 2 * math.pi\n",
        "  Ly = 2 * math.pi\n",
        "\n",
        "  dx = Lx / W\n",
        "  dy = Ly / H\n",
        "  dt = T / steps\n",
        "\n",
        "  # Generate smoother initial conditions\n",
        "  u0 = generate_smooth_random_field(N, H, W, strength=0.3, cutoff=10.0, device=device)\n",
        "  v0 = generate_smooth_random_field(N, H, W, strength=0.3, cutoff=10.0, device=device)\n",
        "\n",
        "  u = u0.clone()\n",
        "  v = v0.clone()\n",
        "\n",
        "  # Time integration with stability checks\n",
        "  for step in range(steps):\n",
        "    u, v = rk4_step(u, v, dt, nu, dx, dy)\n",
        "\n",
        "    # Check for instabilities and clamp\n",
        "    if torch.isnan(u).any() or torch.isnan(v).any():\n",
        "      print(f\"Warning: NaN detected at step {step}\")\n",
        "      break\n",
        "\n",
        "    # To prevent extreme values during evolution\n",
        "    u = torch.clamp(u, -5.0, 5.0)\n",
        "    v = torch.clamp(v, -5.0, 5.0)\n",
        "\n",
        "  X = torch.stack([u0, v0], dim=1)  # (N, 2, H, W)\n",
        "  Y = torch.stack([u, v], dim=1)    # (N, 2, H, W)\n",
        "\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "fthUNa1NE8le"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FNO2D Layer and Model"
      ],
      "metadata": {
        "id": "KXN60nNZCvYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralConv2d(nn.Module):\n",
        "  \"\"\"FIXED Fourier layer with proper initialization and stability.\"\"\"\n",
        "\n",
        "  def __init__(self, in_channels: int, out_channels: int, modes_x: int, modes_y: int):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.modes_x = modes_x\n",
        "    self.modes_y = modes_y\n",
        "\n",
        "    # FIXED: Much smaller initialization for spectral weights\n",
        "    scale = 1.0 / (in_channels * out_channels)\n",
        "    init_std = scale / math.sqrt(modes_x * modes_y)\n",
        "\n",
        "    # Complex weights as real parameters\n",
        "    self.weight_real = nn.Parameter(torch.randn(in_channels, out_channels, modes_x, modes_y) * init_std)\n",
        "    self.weight_imag = nn.Parameter(torch.randn(in_channels, out_channels, modes_x, modes_y) * init_std)\n",
        "\n",
        "  def compl_mul2d(self, a, b_real, b_imag):\n",
        "    \"\"\"Complex multiplication with stability checks.\"\"\"\n",
        "    # a: (B, Cin, mx, my) - complex\n",
        "    # b: (Cin, Cout, mx, my) - real and imag parts\n",
        "    res_real = torch.einsum(\"bixy,ioxy->boxy\", a.real, b_real) - torch.einsum(\"bixy,ioxy->boxy\", a.imag, b_imag)\n",
        "    res_imag = torch.einsum(\"bixy,ioxy->boxy\", a.real, b_imag) + torch.einsum(\"bixy,ioxy->boxy\", a.imag, b_real)\n",
        "\n",
        "    # Stability: clamp extreme values\n",
        "    res_real = torch.clamp(res_real, -1e6, 1e6)\n",
        "    res_imag = torch.clamp(res_imag, -1e6, 1e6)\n",
        "\n",
        "    return torch.complex(res_real, res_imag)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, C, H, W = x.shape\n",
        "\n",
        "    # FIXED: Use standard normalization\n",
        "    x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "    out_ft = torch.zeros(B, self.out_channels, H, W // 2 + 1,\n",
        "                        device=x.device, dtype=torch.complex64)\n",
        "\n",
        "    mx = min(self.modes_x, H // 2)\n",
        "    my = min(self.modes_y, W // 2 + 1)\n",
        "\n",
        "    # low-frequency block [0:mx, 0:my]\n",
        "    out_ft[:, :, :mx, :my] = self.compl_mul2d(\n",
        "      x_ft[:, :, :mx, :my],\n",
        "      self.weight_real[:, :, :mx, :my],\n",
        "      self.weight_imag[:, :, :mx, :my]\n",
        "    )\n",
        "\n",
        "    # high-frequency block [-mx:, 0:my] only if mx > 0\n",
        "    if mx > 0 and mx < H // 2:\n",
        "      out_ft[:, :, -mx:, :my] = self.compl_mul2d(\n",
        "          x_ft[:, :, -mx:, :my],\n",
        "          self.weight_real[:, :, :mx, :my],\n",
        "          self.weight_imag[:, :, :mx, :my]\n",
        "      )\n",
        "\n",
        "    # FIXED: Standard inverse transform\n",
        "    x_out = torch.fft.irfft2(out_ft, s=(H, W))\n",
        "\n",
        "    return x_out"
      ],
      "metadata": {
        "id": "INZgDcM0C9WB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FNO2D(nn.Module):\n",
        "  def __init__(self, in_channels=2, width=32, modes_x=16, modes_y=16, layers=4, out_channels=2):\n",
        "    super().__init__()\n",
        "    self.width = width\n",
        "    self.fc0 = nn.Conv2d(in_channels + 2, width, kernel_size=1) # +2 for positional encodings\n",
        "    nn.init.kaiming_normal_(self.fc0.weight, nonlinearity='linear')\n",
        "    nn.init.zeros_(self.fc0.bias)\n",
        "\n",
        "    # Initialize SpectralConv2d with width as the input channels\n",
        "    self.spectral_layers = nn.ModuleList([SpectralConv2d(width, width, modes_x, modes_y) for _ in range(layers)])\n",
        "    self.w_layers = nn.ModuleList([nn.Conv2d(width, width, kernel_size=1) for _ in range(layers)])\n",
        "\n",
        "    for w in self.w_layers:\n",
        "      nn.init.kaiming_normal_(w.weight) # Removed nonlinearity='gelu'\n",
        "      nn.init.zeros_(w.bias)\n",
        "\n",
        "    self.act = nn.GELU()\n",
        "\n",
        "    self.fc1 = nn.Conv2d(width, 64, kernel_size=1)\n",
        "    self.fc2 = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    nn.init.kaiming_normal_(self.fc1.weight) # Removed nonlinearity='gelu'\n",
        "    nn.init.zeros_(self.fc1.bias)\n",
        "\n",
        "    nn.init.normal_(self.fc2.weight, std=1e-3)\n",
        "    nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x: (B, 2, H, W)\n",
        "    B, C, H, W = x.shape\n",
        "\n",
        "    # positional encodings (normalized coords)\n",
        "    gridx = torch.linspace(0, 1, W, device=x.device).view(1, 1, 1, W).repeat(B, 1, H, 1)\n",
        "    gridy = torch.linspace(0, 1, H, device=x.device).view(1, 1, H, 1).repeat(B, 1, 1, W)\n",
        "\n",
        "    x = torch.cat([x, gridx, gridy], dim=1)\n",
        "    x = self.fc0(x)\n",
        "\n",
        "    for spec, w in zip(self.spectral_layers, self.w_layers):\n",
        "      res = x\n",
        "      y1 = spec(x)\n",
        "      y2 = w(x)\n",
        "      x = self.act(y1 + y2 + res)\n",
        "\n",
        "\n",
        "    x = self.act(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "K-L7JzFiDDoL"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration"
      ],
      "metadata": {
        "id": "BOlODYj4DELV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "  H: int = 64\n",
        "  W: int = 64\n",
        "  train_N: int = 256\n",
        "  val_N: int = 32\n",
        "  T: float = 0.1  # REDUCED time to prevent extreme values\n",
        "  steps: int = 50  # REDUCED steps\n",
        "  nu: float = 0.01\n",
        "  batch_size: int = 8\n",
        "  epochs: int = 20\n",
        "  lr: float = 1e-4  # MUCH LOWER learning rate\n",
        "  weight_decay: float = 1e-5\n",
        "  modes_x: int = 8  # REDUCED modes\n",
        "  modes_y: int = 8  # REDUCED modes\n",
        "  width: int = 32\n",
        "  layers: int = 3  # REDUCED layers\n",
        "  out_dir: str = \"artifacts\""
      ],
      "metadata": {
        "id": "Ly-P_0j7DLUB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "9-JOfwgpGcED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BurgersDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, N, H, W, T, steps, nu, device):\n",
        "    super().__init__()\n",
        "    print(f\"Generating {N} samples...\")\n",
        "    self.X, self.Y = synthesize_dataset(N, H, W, T, steps, nu, device=device)\n",
        "\n",
        "    # Check for NaN/Inf in generated data\n",
        "    if torch.isnan(self.X).any() or torch.isnan(self.Y).any():\n",
        "      raise ValueError(\"NaN found in generated dataset!\")\n",
        "    if torch.isinf(self.X).any() or torch.isinf(self.Y).any():\n",
        "      raise ValueError(\"Inf found in generated dataset!\")\n",
        "\n",
        "    # Conservative normalization\n",
        "    self.X_mean = self.X.mean()\n",
        "    self.X_std = self.X.std() + 1e-8\n",
        "    self.Y_mean = self.Y.mean()\n",
        "    self.Y_std = self.Y.std() + 1e-8\n",
        "\n",
        "    self.X = (self.X - self.X_mean) / self.X_std\n",
        "    self.Y = (self.Y - self.Y_mean) / self.Y_std\n",
        "\n",
        "    print(f\"Data stats - X: mean={self.X.mean():.4f}, std={self.X.std():.4f}\")\n",
        "    print(f\"Data stats - Y: mean={self.Y.mean():.4f}, std={self.Y.std():.4f}\")\n",
        "    print(f\"Data ranges - X: [{self.X.min():.4f}, {self.X.max():.4f}]\")\n",
        "    print(f\"Data ranges - Y: [{self.Y.min():.4f}, {self.Y.max():.4f}]\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.Y[idx]"
      ],
      "metadata": {
        "id": "P7K9162bGdeS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train, Evalute and Plot"
      ],
      "metadata": {
        "id": "12DxAmO1DRDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, opt, scheduler=None):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "\n",
        "  pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
        "  for X, Y in pbar:\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    if torch.isnan(X).any() or torch.isnan(Y).any():\n",
        "      print(\"Warning: NaN in input data, skipping batch\")\n",
        "      continue\n",
        "\n",
        "    opt.zero_grad()\n",
        "    pred = model(X)\n",
        "\n",
        "    if torch.isnan(pred).any():\n",
        "        print(\"Warning: NaN in model output, skipping batch\")\n",
        "        continue\n",
        "\n",
        "    loss = F.mse_loss(pred, Y)\n",
        "\n",
        "    if torch.isnan(loss) or torch.isinf(loss):\n",
        "      print(\"Warning: NaN/Inf loss detected, skipping batch\")\n",
        "      continue\n",
        "\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    num_batches += 1\n",
        "\n",
        "    pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
        "\n",
        "  if scheduler is not None:\n",
        "    scheduler.step()\n",
        "\n",
        "  return total_loss / max(num_batches, 1)"
      ],
      "metadata": {
        "id": "88FItX-3DTbG"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "  model.eval()\n",
        "  total = 0.0\n",
        "  count = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, Y in loader:\n",
        "      X = X.to(device)\n",
        "      Y = Y.to(device)\n",
        "\n",
        "      pred = model(X)\n",
        "\n",
        "      if torch.isnan(pred).any():\n",
        "        continue\n",
        "\n",
        "      loss = F.mse_loss(pred, Y)\n",
        "\n",
        "      if not torch.isnan(loss) and not torch.isinf(loss):\n",
        "        total += loss.item() * X.size(0)\n",
        "        count += X.size(0)\n",
        "\n",
        "  return total / max(count, 1) if count > 0 else float('inf')"
      ],
      "metadata": {
        "id": "cRhNORtJHTAO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_plot(sample_in, sample_true, sample_pred, out_path):\n",
        "  \"\"\"Plot u and v components side by side.\"\"\"\n",
        "  u0, v0 = sample_in[0], sample_in[1]\n",
        "  uT_true, vT_true = sample_true[0], sample_true[1]\n",
        "  uT_pred, vT_pred = sample_pred[0], sample_pred[1]\n",
        "\n",
        "  fig, axs = plt.subplots(2, 3, figsize=(15, 8))\n",
        "\n",
        "  # U component\n",
        "  im0 = axs[0,0].imshow(u0, origin='lower', cmap='RdBu_r')\n",
        "  axs[0,0].set_title('u₀ (Initial)')\n",
        "  fig.colorbar(im0, ax=axs[0,0], fraction=0.046)\n",
        "\n",
        "  im1 = axs[0,1].imshow(uT_true, origin='lower', cmap='RdBu_r')\n",
        "  axs[0,1].set_title('u(T) True')\n",
        "  fig.colorbar(im1, ax=axs[0,1], fraction=0.046)\n",
        "\n",
        "  im2 = axs[0,2].imshow(uT_pred, origin='lower', cmap='RdBu_r')\n",
        "  axs[0,2].set_title('u(T) Predicted')\n",
        "  fig.colorbar(im2, ax=axs[0,2], fraction=0.046)\n",
        "\n",
        "  # V component\n",
        "  im3 = axs[1,0].imshow(v0, origin='lower', cmap='RdBu_r')\n",
        "  axs[1,0].set_title('v₀ (Initial)')\n",
        "  fig.colorbar(im3, ax=axs[1,0], fraction=0.046)\n",
        "\n",
        "  im4 = axs[1,1].imshow(vT_true, origin='lower', cmap='RdBu_r')\n",
        "  axs[1,1].set_title('v(T) True')\n",
        "  fig.colorbar(im4, ax=axs[1,1], fraction=0.046)\n",
        "\n",
        "  im5 = axs[1,2].imshow(vT_pred, origin='lower', cmap='RdBu_r')\n",
        "  axs[1,2].set_title('v(T) Predicted')\n",
        "  fig.colorbar(im5, ax=axs[1,2], fraction=0.046)\n",
        "\n",
        "  for ax in axs.flat:\n",
        "      ax.set_xticks([])\n",
        "      ax.set_yticks([])\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(out_path, dpi=150, bbox_inches='tight')\n",
        "  plt.close(fig)"
      ],
      "metadata": {
        "id": "VLB3gYrdHmj4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(train_losses, val_losses, out_path):\n",
        "  \"\"\"Plot training and validation loss curves.\"\"\"\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "  epochs = range(1, len(train_losses) + 1)\n",
        "  ax.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
        "  ax.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
        "\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('MSE Loss')\n",
        "  ax.set_title('Training Progress')\n",
        "  ax.legend()\n",
        "  ax.grid(True, alpha=0.3)\n",
        "\n",
        "  # Only use log scale if all losses are positive and finite\n",
        "  valid_losses = [l for l in train_losses + val_losses if l > 0 and not math.isinf(l)]\n",
        "  if valid_losses:\n",
        "    ax.set_yscale('log')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(out_path, dpi=150, bbox_inches='tight')\n",
        "  plt.close(fig)"
      ],
      "metadata": {
        "id": "5AbO1kbtQzc9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main:\n",
        "Make dataset -> Train -> Evaluation -> Plot"
      ],
      "metadata": {
        "id": "uz7KiD9FDTn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # Set seeds for reproducibility\n",
        "  SEED = 42\n",
        "  random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  cfg = Config()\n",
        "  os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "\n",
        "  print(f\"Device: {device}\")\n",
        "  print(\"=\"*50)\n",
        "\n",
        "  print(\"Generating datasets...\")\n",
        "  train_ds = BurgersDataset(cfg.train_N, cfg.H, cfg.W, cfg.T, cfg.steps, cfg.nu, device=device)\n",
        "  val_ds = BurgersDataset(cfg.val_N, cfg.H, cfg.W, cfg.T, cfg.steps, cfg.nu, device=device)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n",
        "  val_loader = torch.utils.data.DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False)\n",
        "\n",
        "  print(\"\\nBuilding model...\")\n",
        "  model = FNO2D(\n",
        "      in_channels=2,\n",
        "      width=cfg.width,\n",
        "      modes_x=cfg.modes_x,\n",
        "      modes_y=cfg.modes_y,\n",
        "      layers=cfg.layers,\n",
        "      out_channels=2\n",
        "  ).to(device)\n",
        "\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  print(f\"Total parameters: {total_params:,}\")\n",
        "\n",
        "  # Conservative optimizer settings\n",
        "  opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=cfg.epochs)\n",
        "\n",
        "  print(f\"\\nStarting training for {cfg.epochs} epochs with early stopping...\")\n",
        "  print(\"=\"*50)\n",
        "\n",
        "  best_val = float('inf')\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  patience = 10  # Number of epochs to wait for improvement\n",
        "  epochs_no_improve = 0\n",
        "\n",
        "  for epoch in range(1, cfg.epochs + 1):\n",
        "    tr = train_one_epoch(model, train_loader, opt, scheduler)\n",
        "    va = evaluate(model, val_loader)\n",
        "\n",
        "    train_losses.append(tr)\n",
        "    val_losses.append(va)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | train MSE {tr:.6f} | val MSE {va:.6f} | lr {opt.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "    if va < best_val and not math.isnan(va) and not math.isinf(va):\n",
        "        best_val = va\n",
        "        torch.save(model.state_dict(), os.path.join(cfg.out_dir, \"fno2d_burgers.pt\"))\n",
        "        print(f\"  → New best model saved! (val loss: {va:.6f})\")\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    if epochs_no_improve == patience:\n",
        "        print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
        "        break\n",
        "\n",
        "  # Plot training curves\n",
        "  plot_training_curves(train_losses, val_losses, os.path.join(cfg.out_dir, \"training_curves.png\"))\n",
        "\n",
        "  # Load best model for evaluation\n",
        "  if os.path.exists(os.path.join(cfg.out_dir, \"fno2d_burgers.pt\")):\n",
        "    model.load_state_dict(torch.load(os.path.join(cfg.out_dir, \"fno2d_burgers.pt\"), map_location=device))\n",
        "    print(f\"\\nLoaded best model (val loss: {best_val:.6f})\")\n",
        "  else:\n",
        "    print(\"No saved model found, using final model\")\n",
        "    torch.save(model.state_dict(), os.path.join(cfg.out_dir, \"fno2d_burgers.pt\"))\n",
        "\n",
        "  # Qualitative evaluation\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    X, Y = next(iter(val_loader))\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "    P = model(X)\n",
        "\n",
        "  # Save comparison plot\n",
        "  out_plot = os.path.join(cfg.out_dir, \"qualitative_comparison.png\")\n",
        "  quick_plot(X[0].cpu().numpy(), Y[0].cpu().numpy(), P[0].cpu().numpy(), out_plot)\n",
        "\n",
        "  print(f\"\\n\" + \"=\"*50)\n",
        "  print(f\"Training completed!\")\n",
        "  print(f\"Best validation loss: {best_val:.6f}\")\n",
        "  print(f\"Model saved to: {os.path.join(cfg.out_dir, 'fno2d_burgers.pt')}\")\n",
        "  print(f\"Training curves: {os.path.join(cfg.out_dir, 'training_curves.png')}\")\n",
        "  print(f\"Qualitative results: {out_plot}\")"
      ],
      "metadata": {
        "id": "DLWiRyM7H7Ci"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYE0uCgvIcAs",
        "outputId": "f7affc7f-0d69-4862-d511-0bdaef31ba05"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "==================================================\n",
            "Generating datasets...\n",
            "Generating 256 samples...\n",
            "Data stats - X: mean=0.0000, std=1.0000\n",
            "Data stats - Y: mean=-0.0000, std=1.0000\n",
            "Data ranges - X: [-4.7879, 4.7834]\n",
            "Data ranges - Y: [-6.4223, 5.8358]\n",
            "Generating 32 samples...\n",
            "Data stats - X: mean=-0.0000, std=1.0000\n",
            "Data stats - Y: mean=-0.0000, std=1.0000\n",
            "Data ranges - X: [-4.3759, 4.4995]\n",
            "Data ranges - Y: [-4.9949, 5.0288]\n",
            "\n",
            "Building model...\n",
            "Total parameters: 398,786\n",
            "\n",
            "Starting training for 20 epochs with early stopping...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train MSE 0.889266 | val MSE 0.767413 | lr 9.94e-05\n",
            "  → New best model saved! (val loss: 0.767413)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 | train MSE 0.626617 | val MSE 0.463914 | lr 9.76e-05\n",
            "  → New best model saved! (val loss: 0.463914)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 | train MSE 0.319986 | val MSE 0.187536 | lr 9.46e-05\n",
            "  → New best model saved! (val loss: 0.187536)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | train MSE 0.132630 | val MSE 0.101518 | lr 9.05e-05\n",
            "  → New best model saved! (val loss: 0.101518)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 | train MSE 0.093194 | val MSE 0.089403 | lr 8.54e-05\n",
            "  → New best model saved! (val loss: 0.089403)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 | train MSE 0.087624 | val MSE 0.087067 | lr 7.94e-05\n",
            "  → New best model saved! (val loss: 0.087067)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07 | train MSE 0.086138 | val MSE 0.086279 | lr 7.27e-05\n",
            "  → New best model saved! (val loss: 0.086279)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08 | train MSE 0.085476 | val MSE 0.085771 | lr 6.55e-05\n",
            "  → New best model saved! (val loss: 0.085771)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09 | train MSE 0.085080 | val MSE 0.085498 | lr 5.78e-05\n",
            "  → New best model saved! (val loss: 0.085498)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | train MSE 0.084823 | val MSE 0.085311 | lr 5.00e-05\n",
            "  → New best model saved! (val loss: 0.085311)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | train MSE 0.084646 | val MSE 0.085189 | lr 4.22e-05\n",
            "  → New best model saved! (val loss: 0.085189)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 | train MSE 0.084510 | val MSE 0.085082 | lr 3.45e-05\n",
            "  → New best model saved! (val loss: 0.085082)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 | train MSE 0.084410 | val MSE 0.085005 | lr 2.73e-05\n",
            "  → New best model saved! (val loss: 0.085005)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 | train MSE 0.084333 | val MSE 0.084955 | lr 2.06e-05\n",
            "  → New best model saved! (val loss: 0.084955)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 | train MSE 0.084281 | val MSE 0.084922 | lr 1.46e-05\n",
            "  → New best model saved! (val loss: 0.084922)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 | train MSE 0.084241 | val MSE 0.084892 | lr 9.55e-06\n",
            "  → New best model saved! (val loss: 0.084892)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 | train MSE 0.084214 | val MSE 0.084880 | lr 5.45e-06\n",
            "  → New best model saved! (val loss: 0.084880)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 | train MSE 0.084199 | val MSE 0.084870 | lr 2.45e-06\n",
            "  → New best model saved! (val loss: 0.084870)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 | train MSE 0.084189 | val MSE 0.084865 | lr 6.16e-07\n",
            "  → New best model saved! (val loss: 0.084865)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 | train MSE 0.084184 | val MSE 0.084863 | lr 0.00e+00\n",
            "  → New best model saved! (val loss: 0.084863)\n",
            "\n",
            "Loaded best model (val loss: 0.084863)\n",
            "\n",
            "==================================================\n",
            "Training completed!\n",
            "Best validation loss: 0.084863\n",
            "Model saved to: artifacts/fno2d_burgers.pt\n",
            "Training curves: artifacts/training_curves.png\n",
            "Qualitative results: artifacts/qualitative_comparison.png\n"
          ]
        }
      ]
    }
  ]
}